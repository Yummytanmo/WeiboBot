"""
Workflow Frontend API - åŸºäºLangGraph
æä¾›workflowæ‰§è¡Œå’Œç®¡ç†çš„HTTPæ¥å£
"""
import threading
from contextlib import redirect_stdout
from datetime import datetime
from enum import Enum
from io import StringIO
from typing import Dict, List, Optional, Any, Tuple
from uuid import uuid4

from fastapi import FastAPI, HTTPException
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel

# å¯¼å…¥LangGraph workflowç³»ç»Ÿ
from workflow import (
    create_daily_schedule_graph,
    create_post_review_graph,
    create_browse_interaction_graph,
    create_daily_agent_graph,
    run_graph,
    LANGGRAPH_AVAILABLE,
)

app = FastAPI(title="Workflow Frontend API")

# CORSé…ç½®
app.add_middleware(
    CORSMiddleware,
    allow_origins=["http://localhost:5173"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)


class WorkflowType(str, Enum):
    """Workflowç±»å‹æšä¸¾"""
    DAILY_SCHEDULE = "daily_schedule"
    POST_REVIEW = "post_review"
    BROWSE_INTERACTION = "browse_interaction"
    DAILY_AGENT = "daily_agent"


class WorkflowRequest(BaseModel):
    """Workflowæ‰§è¡Œè¯·æ±‚"""
    workflow: WorkflowType
    agent_id: str
    # é€šç”¨å‚æ•°
    llm_model: str = "gpt-4o-mini"
    llm_temperature: float = 0.3
    tool_timeout: float = 600.0
    # Postç›¸å…³
    current_post_topic: Optional[str] = None
    current_post_notes: Optional[str] = None
    max_review_rounds: int = 2
    auto_post: bool = True
    # Scheduleç›¸å…³
    min_slots: int = 3
    max_slots: int = 5
    start_time: str = "09:00"
    end_time: str = "22:00"
    # Browseç›¸å…³
    max_interactions: int = 5


class WorkflowStatus(str, Enum):
    """WorkflowçŠ¶æ€"""
    PENDING = "pending"
    RUNNING = "running"
    COMPLETED = "completed"
    FAILED = "failed"


class NodeStatus(BaseModel):
    """èŠ‚ç‚¹æ‰§è¡ŒçŠ¶æ€"""
    id: str
    label: str
    status: WorkflowStatus
    started_at: Optional[datetime] = None
    finished_at: Optional[datetime] = None
    duration: Optional[float] = None
    error: Optional[str] = None


class WorkflowRun(BaseModel):
    """Workflowæ‰§è¡Œè®°å½•"""
    id: str
    workflow: WorkflowType
    status: WorkflowStatus
    params: Dict[str, Any]
    created_at: datetime
    started_at: Optional[datetime] = None
    finished_at: Optional[datetime] = None
    logs: str = ""
    result: Optional[Dict[str, Any]] = None
    error: Optional[str] = None
    current_node: Optional[str] = None
    # æ‰§è¡Œå›¾æ•°æ®
    nodes: List[NodeStatus] = []
    edges: List[Dict[str, str]] = []
    
    class Config:
        arbitrary_types_allowed = True


ICON_MAP = {
    "fetch_feed": "ğŸ“¥",
    "summarize_trending": "ğŸ“Š",
    "generate_schedule": "ğŸ“…",
    "compose": "âœï¸",
    "compose_post": "âœï¸",
    "review": "ğŸ‘ï¸",
    "review_post": "ğŸ‘ï¸",
    "post": "ğŸš€",
    "post_weibo": "ğŸš€",
    "decide": "ğŸ¤”",
    "decide_interactions": "ğŸ¤”",
    "execute": "ğŸ’¬",
    "execute_interactions": "ğŸ’¬",
}


# å­˜å‚¨workflowè¿è¡Œè®°å½•
_runs: Dict[str, WorkflowRun] = {}
_runs_lock = threading.Lock()


def _get_workflow_graph(workflow_type: WorkflowType):
    """æ ¹æ®ç±»å‹è·å–workflowå›¾"""
    if not LANGGRAPH_AVAILABLE:
        raise HTTPException(status_code=500, detail="LangGraphæœªå®‰è£…ï¼Œè¯·è¿è¡Œ: pip install langgraph")
    
    graph_creators = {
        WorkflowType.DAILY_SCHEDULE: create_daily_schedule_graph,
        WorkflowType.POST_REVIEW: create_post_review_graph,
        WorkflowType.BROWSE_INTERACTION: create_browse_interaction_graph,
        WorkflowType.DAILY_AGENT: create_daily_agent_graph,
    }
    
    creator = graph_creators.get(workflow_type)
    if not creator:
        raise HTTPException(status_code=400, detail=f"æœªçŸ¥çš„workflowç±»å‹: {workflow_type}")
    
    return creator()


def _massage_node(node_id: Any, data: Optional[Dict[str, Any]] = None) -> Dict[str, Any]:
    """æ„é€ å‰ç«¯èŠ‚ç‚¹æè¿°"""
    text_id = str(node_id)
    label = (data or {}).get("label") or (data or {}).get("name") or text_id.replace("_", " ").title()
    return {
        "id": text_id,
        "label": label,
        "icon": ICON_MAP.get(text_id),
    }


def _extract_graph_structure(graph) -> Tuple[List[Dict[str, Any]], List[Dict[str, Any]]]:
    """
    ä»LangGraphç¼–è¯‘åçš„graphä¸­æå–èŠ‚ç‚¹/è¾¹ç»“æ„ã€‚
    ä»…ä¾èµ–é€šç”¨çš„ get_graph() æ–¹æ³•ï¼Œå°½é‡ä¸å‡å®šå†…éƒ¨å®ç°ã€‚
    """
    nodes: List[Dict[str, Any]] = []
    edges: List[Dict[str, Any]] = []

    # ä¼˜å…ˆä½¿ç”¨ get_graph() æä¾›çš„ networkx å›¾
    if hasattr(graph, "get_graph"):
        nx_graph = graph.get_graph()
        # æå–èŠ‚ç‚¹
        try:
            node_view = getattr(nx_graph, "nodes", None)
            node_iter = node_view(data=True) if callable(node_view) else getattr(node_view, "data", lambda data=True: [])(data=True)
            for node_id, data in list(node_iter):
                node_data = data if isinstance(data, dict) else {}
                nodes.append(_massage_node(node_id, node_data))
        except Exception:
            pass
        # æå–è¾¹
        try:
            is_multi = callable(getattr(nx_graph, "is_multigraph", None)) and nx_graph.is_multigraph()
            edge_view = getattr(nx_graph, "edges", None)
            edge_iter = (
                edge_view(keys=True, data=True) if (callable(edge_view) and is_multi) else
                edge_view(data=True) if callable(edge_view) else
                getattr(edge_view, "data", lambda data=True: [])(data=True)
            )
            for edge in list(edge_iter):
                try:
                    if is_multi:
                        source, target, _key, attr = edge
                    else:
                        source, target, attr = edge
                except Exception:
                    continue
                label = None
                if isinstance(attr, dict):
                    label = attr.get("label") or attr.get("condition") or attr.get("name")
                edges.append({
                    "id": f"{source}->{target}-{len(edges)}",
                    "source": str(source),
                    "target": str(target),
                    "label": label,
                })
        except Exception:
            pass

    # å¦‚æœæœªæˆåŠŸè·å–ï¼Œå°è¯• fallbackï¼ˆç©ºï¼‰
    if not nodes:
        return [], []
    return nodes, edges


def _get_workflow_graph_layout(workflow_type: WorkflowType) -> Dict[str, Any]:
    """
    è·å–workflowçš„èŠ‚ç‚¹å’Œè¾¹å¸ƒå±€ã€‚
    ä¼˜å…ˆä»LangGraphçœŸå®ç»“æ„æå–ï¼Œæ— æ³•æå–æ—¶è¿”å›ç©ºèŠ‚ç‚¹/è¾¹ï¼Œ
    ç”±å‰ç«¯æ‰§è¡Œè‡ªåŠ¨å¸ƒå±€ã€‚
    """
    try:
        graph = _get_workflow_graph(workflow_type)
        nodes, edges = _extract_graph_structure(graph)
        if nodes:
            return {"nodes": nodes, "edges": edges}
    except Exception as exc:
        # æ•è·ä½†ä¸é˜»æ–­ï¼Œè®©å‰ç«¯æœ‰æœºä¼šä½¿ç”¨ç®€æ˜“fallback
        print(f"âš ï¸ æ— æ³•æå–workflowå›¾ç»“æ„: {exc}")

    # fallbackï¼šä»…æä¾›åŸºæœ¬ä¿¡æ¯ï¼ˆå‰ç«¯ä¼šè‡ªåŠ¨å¸ƒå±€ï¼‰
    fallbacks = {
        WorkflowType.DAILY_SCHEDULE: ["fetch_feed", "summarize_trending", "generate_schedule"],
        WorkflowType.POST_REVIEW: ["compose", "review", "post"],
        WorkflowType.BROWSE_INTERACTION: ["fetch_feed", "decide", "execute"],
        WorkflowType.DAILY_AGENT: [
            "fetch_feed", "summarize_trending", "generate_schedule",
            "compose_post", "review_post", "post_weibo",
            "decide_interactions", "execute_interactions",
        ],
    }
    node_ids = fallbacks.get(workflow_type, [])
    return {
        "nodes": [_massage_node(node_id) for node_id in node_ids],
        "edges": [],
    }


def _build_initial_state(request: WorkflowRequest) -> Dict[str, Any]:
    """æ„å»ºåˆå§‹çŠ¶æ€"""
    return {
        "agent_id": request.agent_id,
        "llm_model": request.llm_model,
        "llm_temperature": request.llm_temperature,
        "tool_timeout": request.tool_timeout,
        "current_post_topic": request.current_post_topic,
        "current_post_notes": request.current_post_notes,
        "max_review_rounds": request.max_review_rounds,
        "auto_post": request.auto_post,
        "min_slots": request.min_slots,
        "max_slots": request.max_slots,
        "start_time": request.start_time,
        "end_time": request.end_time,
        "max_interactions": request.max_interactions,
    }


def _execute_workflow(run_id: str, request: WorkflowRequest):
    """åå°æ‰§è¡Œworkflow"""
    with _runs_lock:
        run = _runs[run_id]
        run.status = WorkflowStatus.RUNNING
        run.started_at = datetime.utcnow()
    
    try:
        # è·å–workflowå›¾
        graph = _get_workflow_graph(request.workflow)
        
        # æ„å»ºåˆå§‹çŠ¶æ€
        initial_state = _build_initial_state(request)
        
        # æ•è·æ—¥å¿—
        log_stream = StringIO()
        with redirect_stdout(log_stream):
            # æ‰§è¡Œworkflow
            final_state = run_graph(graph, initial_state)
        
        # æ›´æ–°ç»“æœ
        with _runs_lock:
            run.status = WorkflowStatus.COMPLETED
            run.finished_at = datetime.utcnow()
            run.logs = log_stream.getvalue()
            run.result = final_state
            run.current_node = final_state.get("current_node")
    
    except Exception as e:
        with _runs_lock:
            run.status = WorkflowStatus.FAILED
            run.finished_at = datetime.utcnow()
            run.error = str(e)


@app.get("/")
async def root():
    """å¥åº·æ£€æŸ¥"""
    return {
        "service": "Workflow Frontend API",
        "langgraph_available": LANGGRAPH_AVAILABLE,
    }


@app.get("/graph/{workflow_type}")
async def get_workflow_graph_layout(workflow_type: WorkflowType):
    """è·å–workflowçš„èŠ‚ç‚¹å’Œè¾¹å¸ƒå±€"""
    return _get_workflow_graph_layout(workflow_type)


@app.post("/trigger")
async def trigger_workflow(request: WorkflowRequest):
    """è§¦å‘workflowæ‰§è¡Œ"""
    # åˆ›å»ºè¿è¡Œè®°å½•
    run_id = str(uuid4())
    run = WorkflowRun(
        id=run_id,
        workflow=request.workflow,
        status=WorkflowStatus.PENDING,
        params=request.dict(),
        created_at=datetime.utcnow(),
    )
    
    with _runs_lock:
        _runs[run_id] = run
    
    # åå°æ‰§è¡Œ
    thread = threading.Thread(target=_execute_workflow, args=(run_id, request))
    thread.daemon = True
    thread.start()
    
    return {"run_id": run_id, "status": "triggered"}


@app.get("/runs")
async def list_runs():
    """è·å–æ‰€æœ‰è¿è¡Œè®°å½•"""
    with _runs_lock:
        return {
            "runs": [
                {
                    "id": run.id,
                    "workflow": run.workflow,
                    "status": run.status,
                    "created_at": run.created_at.isoformat(),
                    "started_at": run.started_at.isoformat() if run.started_at else None,
                    "finished_at": run.finished_at.isoformat() if run.finished_at else None,
                }
                for run in _runs.values()
            ]
        }


@app.get("/run/{run_id}")
async def get_run(run_id: str):
    """è·å–è¿è¡Œè¯¦æƒ…"""
    with _runs_lock:
        run = _runs.get(run_id)
        if not run:
            raise HTTPException(status_code=404, detail="Run not found")
        
        return run.dict()


@app.delete("/run/{run_id}")
async def delete_run(run_id: str):
    """åˆ é™¤è¿è¡Œè®°å½•"""
    with _runs_lock:
        if run_id not in _runs:
            raise HTTPException(status_code=404, detail="Run not found")
        del _runs[run_id]
    
    return {"status": "deleted"}


if __name__ == "__main__":
    import uvicorn
    uvicorn.run(app, host="0.0.0.0", port=8000)
